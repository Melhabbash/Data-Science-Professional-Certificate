---
title: "Forest Cover Type Prediction"
subtitle: '**HarvardX Data Science Professional Certificate: PH125.9x**  \newline Data Science Initiative   \newline The Palestinian Central Bureau of Statistics (PCBS)   \newline  Arab American University of Palestine (AAUP) \newline'

author: "Mohammed K. M. Elhabbash " 
date: "_`r format(Sys.Date(), '%d %B, %Y')`_"
output:
  pdf_document:
    df_print: kable
    toc: true
    toc_depth: 3
    fig_width: 12
    fig_height: 6

header-includes:
   - \usepackage[font={footnotesize,it}, labelfont={bf}]{caption}

include-before: '`\newpage{}`{=latex}'
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE , warning = FALSE, message = FALSE,
                      fig.align="center", out.width="60%")
# set time 
Sys.setenv(TZ='Europe/Berlin')
################## Install Basic Package required -- 
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggthemes)) install.packages("ggthemes", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(rmarkdown)) install.packages("rmarkdown", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(ellipse)) install.packages("ellipse", repos = "http://cran.us.r-project.org")
# if(!require(ggord)) install.packages("ggord", repos = "http://cran.us.r-project.org")
################## Install Additional Package  used in code
#### Used formattable and kableExtra Package to formate Table
# if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
# if(!require(formattable)) install.packages("formattable", repos = "http://cran.us.r-project.org")

# import libraries
library(tidyverse)   # general
library(caret)       # model
library(dplyr)
library(dslabs)
library(ggcorrplot)  # correlation matrix plot
library(psych)
library(MASS)
# library(ggord)
# library(devtools)

library(data.table)
library(kableExtra)
library(formattable)
library(DescTools)   # descriptive statistics
library(ggthemes)
library(lubridate) ## used to deal with timestamp
library(knitr)
library(rmarkdown)

library(rpart)
library(party)
set_theme <- theme(text = element_text(size=16), panel.border = element_rect(colour="black", linetype = "solid", fill=NA), plot.title = element_text(hjust = 0.5, size = 18), plot.caption = element_text(hjust = 0.5))

# import data set
data <- read.csv("train.csv",stringsAsFactors=T)


```
\newpage 
## 1. Introduction
As a type of artificial intelligence (AI), machine learning (ML) lets software applications predict outcomes without being explicitly programmed to do so. Machine learning algorithms use historical data as input to predict new output values. Prediction and classification of things are the essential and famous applications of machine learning. There are various algorithms used to categorize things, such as Logistic Regression, Naive Bayes, K-Nearest Neighbors, Decision Tree, Support Vector Machines, and Linear discriminant analysis. Studying the Forest Cover Type, in this Paper, uses two algorithms to classify the cover type of forest depending on the data set from [Kaggle](https://www.kaggle.com/c/tabular-playground-series-dec-2021/data). The first is a linear algorithm, Linear discriminant analysis (LDA), the second is a nonlinear algorithm, Classification And Regression Tree (CART). 
To clarify the purpose of this paper, first, we want to investigate specifications and show samples of the data set.

### 1.1 Investigation the dataset
The source of used data set in this paper is from a competition, Playground Prediction Competition, launched in Dec 2021 [Kaggle](https://www.kaggle.com/c/tabular-playground-series-dec-2021/data). The data is artificially generated by a GAN that was trained on data from the Forest Cover Type Prediction. The goal here in this paper is to predict the Cover_Type class for each Id in the data set depending on the rest of data set.
Data set is with dimension of `r dim(data) `. A sample of data set is shown below
```{r glimpse_data, echo=FALSE}
glimpse(data)
```
\
The details of data is described for each column as \  

```{r, table 1, echo=FALSE}
name<-c(
  names(data[1]),
  names(data[2]),
  names(data[3]),
  names(data[4]),
  names(data[5]),
  names(data[6]),
  names(data[7]),
  names(data[8]),
  names(data[9]),
  names(data[10]),
  names(data[11])
  
)

description<-c(
  "A primary key (unique value for each record,row )",
  "Elevation in meters",
  "Aspect in degrees azimuth",
  "Slope in degrees",
  "Horz Dist to nearest surface water features",
  "Vert Dist to nearest surface water features",
  "Horz Dist to nearest roadway",
  "Hillshade index at 9am, summer solstice",
  "Hillshade index at noon, summer solstice",
  "Hillshade index at 3pm, summer solstice",
  "Horz Dist to nearest wildfire ignition points"
  
)
table_1 <- data.frame(Name=name,Describtion=description)
table_1%>%
	kable(
		align = 'l', booktabs = T,format = "latex", linesep = "") %>%
        column_spec(1, color =  "#41729F", bold = T) %>%
        column_spec(2, color =  "#41729F", bold = T) %>%
		
       	kable_styling(full_width = FALSE, position = "left", latex_options = "hold_position")
```

```{r, table 2, echo=FALSE}
name<-c(
  names(data[12]),
  names(data[13]),
  names(data[14]),
  names(data[15]),
  names(data[16]),
  names(data[17]),
  names(data[18]),
  names(data[19]),
  names(data[20]),
  names(data[21]),
  names(data[22]),
  names(data[23]),
  names(data[24]),
  names(data[25]),
  names(data[26]),
  names(data[27]),
  names(data[28]),
  names(data[29]),
  names(data[30]),
  names(data[31]),
  names(data[32]),
  names(data[33]),
  names(data[34]),
  names(data[35]),
  names(data[36]),
  names(data[37]),
  names(data[38]),
  names(data[39]),
  names(data[40]),
  names(data[41]),
  names(data[42]),
  names(data[43]),
  names(data[44]),
  names(data[45]),
  names(data[46]),
  names(data[47]),
  names(data[48]),
  names(data[49]),
  names(data[50]),
  names(data[51]),
  names(data[52]),
  names(data[53]),
  names(data[54]),
  names(data[55]),
  names(data[56])
)


description<-c(
  "Rawah Wilderness Area",
  "Neota Wilderness Area",
  "Comanche Peak Wilderness Area",
  "Cache la Poudre Wilderness Area",
  "Cathedral family - Rock outcrop complex, extremely stony",
  "Vanet - Ratake families complex, very stony",
  "Haploborolis - Rock outcrop complex, rubbly",
  "Ratake family - Rock outcrop complex, rubbly",
  "Vanet family - Rock outcrop complex complex, rubbly",
  "Vanet - Wetmore families - Rock outcrop complex, stony",
  "Gothic family",
  "Supervisor - Limber families complex",
  "Troutville family, very stony",
  "Bullwark - Catamount families - Rock outcrop complex, rubbly",
  "Bullwark - Catamount families - Rock land complex, rubbly",
  "Legault family - Rock land complex, stony",
  "Catamount family -Rock land- Bullwark family complex, rubbly",
  "Pachic Argiborolis - Aquolis complex",
  "Unspecified in the USFS Soil and ELU Survey",
  "Cryaquolis - Cryoborolis complex",
  "Gateview family - Cryaquolis complex",
  "Rogert family, very stony",
  "Typic Cryaquolis - Borohemists complex",
  "Typic Cryaquepts - Typic Cryaquolls complex",
  "Typic Cryaquolls - Leighcan family, till substratum complex",
  "Leighcan family, till substratum, extremely bouldery",
  "Leighcan family, till substratum - Typic Cryaquolls complex",
  "Leighcan family, extremely stony",
  "Leighcan family, warm, extremely stony",
  "Granile - Catamount families complex, very stony",
  "Leighcan family, warm - Rock outcrop complex, extremely stony",
  "Leighcan family - Rock outcrop complex, extremely stony",
  "Como - Legault families complex, extremely stony",
  "Como family -Rock land- Legault family complex, extremely stony",
  "Leighcan - Catamount families complex, extremely stony",
  "Catamount family - Rock outcrop - Leighcan family complex, extremely stony",
  "Leighcan - Catamount families - Rock outcrop complex, extremely stony",
  "Cryorthents - Rock land complex, extremely stony",
  "Cryumbrepts - Rock outcrop - Cryaquepts complex",
  "Bross family - Rock land - Cryumbrepts complex, extremely stony",
  "Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony",
  "Leighcan - Moran families - Cryaquolls complex, extremely stony",
  "Moran family -Cryorthents- Leighcan family complex,extremely stony",
  "Moran family -Cryorthents- Rock land complex, extremely stony",
  "7 types, integers 1 to 7- Forest Cover Type designation"
)
table_2 <- data.frame(Name=name,Describtion=description)
table_2%>%
	kable(
		align = 'l', booktabs = T,format = "latex", linesep = "") %>%
        column_spec(1, color =  "#41729F", bold = T) %>%
        column_spec(2, color =  "#41729F", bold = T) %>%
		
       	kable_styling(full_width = FALSE, position = "left", latex_options = "hold_position")
```
\

In the following some statistics summary of the data, i.e. Min.,1st Qu., Median,Mean,3rd Qu., and Max. for Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, and Horizontal_Distance_To_Fire_Points \



```{r table 3 statistics summary of Elevation Aspect and Slope ,  echo=FALSE}
table_3<-unclass(summary(data[,2:4]))
table_3%>%
	kable(col.names = names(data)[2:4],
        align = 'c', booktabs = T,format = "latex", linesep = "") %>%
        column_spec(1, color =  "#41729F", bold = T) %>%
        column_spec(2, color =  "#41729F", bold = T) %>%
		    column_spec(3, color =  "#41729F", bold = T) %>%
       	kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position")
```

```{r table 4 statistics summary of Horizontal_Distance_To_Hydrology Vertical_Distance_To_Hydrology,  echo=FALSE}
table_4<-unclass(summary(data[,5:6]))
table_4%>%
	kable(table_3,col.names = names(data)[5:6],
		    align = 'c', booktabs = T,format = "latex", linesep = "") %>%
        column_spec(1, color =  "#41729F", bold = T) %>%
        column_spec(2, color =  "#41729F", bold = T) %>%
       	kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position")

```
```{r table 5 statistics summary of Hillshade_9am Hillshade_Noon Hillshade_3pm,  echo=FALSE}
table_5<-unclass(summary(data[,8:10]))
table_5%>%
	kable(col.names = names(data)[8:10],
		    align = 'c', booktabs = T,format = "latex", linesep = "") %>%
        column_spec(1, color =  "#41729F", bold = T) %>%
        column_spec(2, color =  "#41729F", bold = T) %>%
        column_spec(3, color =  "#41729F", bold = T) %>%
		kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position")
```
```{r table 6 statistics summary of Horizontal_Distance_To_Roadways Horizontal_Distance_To_Fire_Points,  echo=FALSE} 
table_6<-unclass(summary(data[,c(7,11)]))

table_6 %>%
	kable(col.names = names(data)[c(7,11)],
	      align = 'c', booktabs = T,format = "latex", linesep = "") %>%
        column_spec(1, color =  "#41729F", bold = T) %>%
        column_spec(2, color =  "#41729F", bold = T) %>%
        kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position")
```
For wilderness area designation, the following table display how many records for each "wilderness area" variable\ 

```{r table 7, echo=FALSE}
table_7 <- data.frame(
  Var = c(names(data[12]), 
          names(data[13]),
          names(data[14]),
          names(data[15])
  ),
  Rec = c(
    length(which(data$Wilderness_Area1==1)),
    length(which(data$Wilderness_Area2==1)),
    length(which(data$Wilderness_Area3==1)),
    length(which(data$Wilderness_Area4==1))
  )
)

table_7 %>% 
  kable(col.names = c("Wilderness area type", "Number of records"), 
      align = 'c', booktabs = T,format = "latex", linesep = "") %>%
      column_spec(1, color =  "#41729F", bold = T) %>%
      column_spec(2, color =  "#41729F", bold = T) %>%
      kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position")
```

For Soil Type  designation, the following table display how many records for each "Soil Type" variable \

```{r table 8, echo=FALSE}
table_8 <- data.frame(
                            c(
                              names(data[16]), 
                              names(data[17]),
                              names(data[18]),
                              names(data[19]),
                              names(data[20]),
                              names(data[21]),
                              names(data[22]),
                              names(data[23]),
                              names(data[24]),
                              names(data[25]),
                              names(data[26]),
                              names(data[27]),
                              names(data[28]),
                              names(data[29]),
                              names(data[30]),
                              names(data[31]),
                              names(data[32]),
                              names(data[33]),
                              names(data[34]),
                              names(data[35]),
                              names(data[36]),
                              names(data[37]),
                              names(data[38]),
                              names(data[39]),
                              names(data[40]),
                              names(data[41]),
                              names(data[42]),
                              names(data[43]),
                              names(data[44]),
                              names(data[45]),
                              names(data[46]),
                              names(data[47]),
                              names(data[48]),
                              names(data[49]),
                              names(data[50]),
                              names(data[51]),
                              names(data[52]),
                              names(data[53]),
                              names(data[54]),
                              names(data[55])
                              ),
                      c(
                        length(which(data$Soil_Type1==1)),
                        length(which(data$Soil_Type2==1)),
                        length(which(data$Soil_Type3==1)),
                        length(which(data$Soil_Type4==1)),
                        length(which(data$Soil_Type5==1)),
                        length(which(data$Soil_Type6==1)),
                        length(which(data$Soil_Type7==1)),
                        length(which(data$Soil_Type8==1)),
                        length(which(data$Soil_Type9==1)),
                        length(which(data$Soil_Type10==1)),
                        length(which(data$Soil_Type11==1)),
                        length(which(data$Soil_Type12==1)),
                        length(which(data$Soil_Type13==1)),
                        length(which(data$Soil_Type14==1)),
                        length(which(data$Soil_Type15==1)),
                        length(which(data$Soil_Type16==1)),
                        length(which(data$Soil_Type17==1)),
                        length(which(data$Soil_Type18==1)),
                        length(which(data$Soil_Type19==1)),
                        length(which(data$Soil_Type20==1)),
                        length(which(data$Soil_Type21==1)),
                        length(which(data$Soil_Type22==1)),
                        length(which(data$Soil_Type23==1)),
                        length(which(data$Soil_Type24==1)),
                        length(which(data$Soil_Type25==1)),
                        length(which(data$Soil_Type26==1)),
                        length(which(data$Soil_Type27==1)),
                        length(which(data$Soil_Type28==1)),
                        length(which(data$Soil_Type29==1)),
                        length(which(data$Soil_Type30==1)),
                        length(which(data$Soil_Type31==1)),
                        length(which(data$Soil_Type32==1)),
                        length(which(data$Soil_Type33==1)),
                        length(which(data$Soil_Type34==1)),
                        length(which(data$Soil_Type35==1)),
                        length(which(data$Soil_Type36==1)),
                        length(which(data$Soil_Type37==1)),
                        length(which(data$Soil_Type38==1)),
                        length(which(data$Soil_Type39==1)),
                        length(which(data$Soil_Type40==1))
                      )
                      )

table_8 %>% 
  kable(col.names = c("Soil type", "Number of records"), 
      align = 'c', booktabs = T,format = "latex", linesep = "") %>%
      column_spec(1, color =  "#41729F", bold = T) %>%
      column_spec(2, color =  "#41729F", bold = T) %>%
      kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position")
```

\newpage 
### 1.2 Wrangling and cleaning data

```{r, copy clean data, echo=FALSE}
Clean_Data<-data
```


1- "Horizontal_Distance_To_Hydrology", " Vertical_Distance_To_Hydrology", "Horizontal_Distance_To_Roadways", \
"Hillshade_9am", "Hillshade_3pm", and "Horizontal_Distance_To_Fire_Point"  have negative values, but the distance should be only a positive value.\

```{r negative values to positive values , echo=FALSE}
index_1<-which(Clean_Data$Horizontal_Distance_To_Hydrology<0)
Clean_Data$Horizontal_Distance_To_Hydrology[index_1]<-Clean_Data$Horizontal_Distance_To_Hydrology[index_1]*-1

index_2<-which(Clean_Data$Vertical_Distance_To_Hydrology<0)
Clean_Data$Vertical_Distance_To_Hydrology[index_2]<-Clean_Data$Vertical_Distance_To_Hydrology[index_2]*-1

index_3<-which(Clean_Data$Horizontal_Distance_To_Roadways<0)
Clean_Data$Horizontal_Distance_To_Roadways[index_3]<-Clean_Data$Horizontal_Distance_To_Roadways[index_3]*-1

index_4<-which(Clean_Data$Hillshade_9am<0)
Clean_Data$Hillshade_9am[index_4]<-Clean_Data$Hillshade_9am[index_4]*-1

index_5<-which(data$Hillshade_3pm<0)
Clean_Data$Hillshade_3pm[index_5]<-Clean_Data$Hillshade_3pm[index_5]*-1

index_6<-which(Clean_Data$Horizontal_Distance_To_Fire_Points<0)
Clean_Data$Horizontal_Distance_To_Fire_Points[index_6]<-Clean_Data$Horizontal_Distance_To_Fire_Points[index_6]*-1
```

2- "Soil_Type7", and "Soil_Type15" are with only 0 value. This means that we can drop these two columns.\  

```{r drop variables with single value -0 value-, echo=FALSE}
Clean_Data<-subset(Clean_Data, select = -c(Soil_Type7,Soil_Type15 ))
```

```{r drop single record, echo=FALSE}
level_5<-which(Clean_Data$Cover_Type==5)
Clean_Data<-Clean_Data[-level_5,]
Clean_Data<-droplevels(Clean_Data)
Clean_Data$Cover_Type<-as.factor(Clean_Data$Cover_Type)
```
3- "Cover_Type" has `r length(level_5)` value for level 5, this means that this single value will appear in the training data set or will appear in validation-data-set, and this will cause a problem in the "train" or in the "predict" function. the solution for this problem is to drop level 5 in Cover_Type, so the levels will be:`r levels(Clean_Data$Cover_Type)` 1,2,3,4,6, and 7. \

### 1.3 Statistic summary and visualizing data after wrangling and cleaning 
Elevation

```{r Figure3 , echo=FALSE, fig.cap="Histogram of Elevation"}
hist(Clean_Data$Elevation, freq=TRUE, col="#41729F", border="white", 
     xlab="Elevation", ylab="Count")
```
```{r Statistic summary of Elevation, echo=FALSE}
samm_Elevation<-summary(Clean_Data$Elevation)
```
 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Elevation[1]` | `r samm_Elevation[2]` |`r samm_Elevation[3]` |`r samm_Elevation[4]`| `r samm_Elevation[5]` | `r samm_Elevation[6]`

\
Aspect

```{r Figure4 , echo=FALSE, fig.cap="Histogram of Aspect"}
hist(Clean_Data$Aspect, freq=TRUE, col="#41729F", border="white", 
     xlab="Aspect", ylab="Count")
```
```{r Statistic summary of Aspect, echo=FALSE}
samm_Aspect<-summary(Clean_Data$Aspect)
```
 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Aspect[1]` | `r samm_Aspect[2]` |`r samm_Aspect[3]` |`r samm_Aspect[4]`| `r samm_Aspect[5]` | `r samm_Aspect[6]`

\
Slope
```{r Figure5 , echo=FALSE, fig.cap="Histogram of Slope"}
hist(Clean_Data$Slope, freq=TRUE, col="#41729F", border="white", 
     xlab="Slope", ylab="Count")
```
```{r Statistic summary of Slope, echo=FALSE}
samm_Slope<-summary(Clean_Data$Slope)
```

 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Slope[1]` | `r samm_Slope[2]` |`r samm_Slope[3]` |`r samm_Slope[4]`| `r samm_Slope[5]` | `r samm_Slope[6]`

\
Horizontal Distance To Hydrology
```{r Figure6 , echo=FALSE, fig.cap="Histogram of Horizontal Distance To Hydrology"}
hist(Clean_Data$Horizontal_Distance_To_Hydrology, freq=TRUE, col="#41729F", border="white", 
     xlab="Horizontal Distance To Hydrology", ylab="Count")
```
```{r Statistic summary of Horizontal Distance To Hydrology, echo=FALSE}
samm_Horizontal_Distance_To_Hydrology<-summary(Clean_Data$Horizontal_Distance_To_Hydrology)
```

 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Horizontal_Distance_To_Hydrology[1]` | `r samm_Horizontal_Distance_To_Hydrology[2]` |`r samm_Horizontal_Distance_To_Hydrology[3]` |`r samm_Horizontal_Distance_To_Hydrology[4]`| `r samm_Horizontal_Distance_To_Hydrology[5]` | `r samm_Horizontal_Distance_To_Hydrology[6]`
 
\  
Vertical Distance To Hydrology
```{r Figure7 , echo=FALSE, fig.cap="Histogram of Vertical Distance To Hydrology"}
hist(Clean_Data$Vertical_Distance_To_Hydrology, freq=TRUE, col="#41729F", border="white", 
     xlab="Vertical Distance To Hydrology", ylab="Count")
```
```{r Statistic summary of Vertical Distance To Hydrology, echo=FALSE}
samm_Vertical_Distance_To_Hydrology<-summary(Clean_Data$Vertical_Distance_To_Hydrology)
```

 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Vertical_Distance_To_Hydrology[1]` | `r samm_Vertical_Distance_To_Hydrology[2]` |`r samm_Vertical_Distance_To_Hydrology[3]` |`r samm_Vertical_Distance_To_Hydrology[4]`| `r samm_Vertical_Distance_To_Hydrology[5]` | `r samm_Vertical_Distance_To_Hydrology[6]`

\
Hillshade 9am
```{r Figure8 , echo=FALSE, fig.cap="Histogram of Hillshade 9am"}
hist(Clean_Data$Hillshade_9am, freq=TRUE, col="#41729F", border="white", 
     xlab="Hillshade 9am", ylab="Count")
```
```{r Statistic summary of Hillshade 9am, echo=FALSE}
samm_Hillshade_9am<-summary(Clean_Data$Hillshade_9am)
```
 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Hillshade_9am[1]` | `r samm_Hillshade_9am[2]` |`r samm_Hillshade_9am[3]` |`r samm_Hillshade_9am[4]`| `r samm_Hillshade_9am[5]` | `r samm_Hillshade_9am[6]`

\
Hillshade Noon
```{r Figure9 , echo=FALSE, fig.cap="Histogram of Hillshade Noon"}
hist(Clean_Data$Hillshade_Noon, freq=TRUE, col="#41729F", border="white", 
     xlab="Hillshade Noon", ylab="Count")
```
```{r Statistic summary of Hillshade Noon, echo=FALSE}
samm_Hillshade_Noon<-summary(Clean_Data$Hillshade_Noon)
```
 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Hillshade_Noon[1]` | `r samm_Hillshade_Noon[2]` |`r samm_Hillshade_Noon[3]` |`r samm_Hillshade_Noon[4]`| `r samm_Hillshade_Noon[5]` | `r samm_Hillshade_Noon[6]`

\
Hillshade 3pm
```{r Figure10 , echo=FALSE, fig.cap="Histogram of Hillshade 3pm"}
hist(Clean_Data$Hillshade_3pm, freq=TRUE, col="#41729F", border="white", 
     xlab="Hillshade 3pm", ylab="Count")
```
```{r Statistic summary of Hillshade 3pm, echo=FALSE}
samm_Hillshade_3pm<-summary(Clean_Data$Hillshade_3pm)
```
 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Hillshade_3pm[1]` | `r samm_Hillshade_3pm[2]` |`r samm_Hillshade_3pm[3]` |`r samm_Hillshade_3pm[4]`| `r samm_Hillshade_3pm[5]` | `r samm_Hillshade_3pm[6]`

\
Horizontal Distance To Roadways
```{r Figure11 , echo=FALSE, fig.cap="Histogram of Horizontal Distance To Roadways"}
hist(Clean_Data$Horizontal_Distance_To_Roadways, freq=TRUE, col="#41729F", border="white", 
     xlab="Horizontal Distance To Roadways", ylab="Count")
```
```{r Statistic summary of Horizontal Distance To Roadways, echo=FALSE}
samm_Horizontal_Distance_To_Roadways<-summary(Clean_Data$Horizontal_Distance_To_Roadways)
```

 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Horizontal_Distance_To_Roadways[1]` | `r samm_Horizontal_Distance_To_Roadways[2]` |`r samm_Horizontal_Distance_To_Roadways[3]` |`r samm_Horizontal_Distance_To_Roadways[4]`| `r samm_Horizontal_Distance_To_Roadways[5]` | `r samm_Horizontal_Distance_To_Roadways[6]`

\
Horizontal Distance To Fire Points
```{r Figure12 , echo=FALSE, fig.cap="Histogram of Horizontal Distance To Fire Points"}
hist(Clean_Data$Horizontal_Distance_To_Fire_Points, freq=TRUE, col="#41729F", border="white", 
     xlab="Horizontal Distance To Fire Points", ylab="Count")
```
```{r statistic summary of Horizontal Distance To Fire Points, echo=FALSE}
samm_Horizontal_Distance_To_Fire_Points<-summary(Clean_Data$Horizontal_Distance_To_Fire_Points)
```

 Min.      | $Q_1$     | Median   | Mean    | $Q_3$     | Max
-----------|-----------|------------|---------|-----------|---------
 `r samm_Horizontal_Distance_To_Fire_Points[1]` | `r samm_Horizontal_Distance_To_Fire_Points[2]` |`r samm_Horizontal_Distance_To_Fire_Points[3]` |`r samm_Horizontal_Distance_To_Fire_Points[4]`| `r samm_Horizontal_Distance_To_Fire_Points[5]` | `r samm_Horizontal_Distance_To_Fire_Points[6]`


### 1.4 Split data into training data set and validation data set

```{r split data into training dataset and validation dataset, echo=FALSE}
Clean_Data$Cover_Type<-as.factor(Clean_Data$Cover_Type)
validation_index <- createDataPartition(Clean_Data$Cover_Type, p=0.20, list=FALSE)
x<-dim(data)
validation_percentage<-round(length(validation_index)/x[1],3)*100
validation_set <- Clean_Data[validation_index,]
training_set <- Clean_Data[-validation_index,]
dim_training_set<-dim(training_set) 
dim_validation_set<-dim(validation_set)
```
 
For the purpose of machine learning we will split our data set into training data which is  (`r 100-validation_percentage`%) of the original data set, and validation data set which is (`r validation_percentage`%) of the original data set, so the training data set has `r dim_training_set[1]` records for each `r dim_training_set[2]` column, while validation data set has `r dim_validation_set[1]` records for each `r dim_validation_set[2]` column. 


The levels of variable Cover_Type is `r levels(training_set$Cover_Type)` , and summary of the class distribution is shown below
```{r summarize the class distribution, echo=FALSE}
percentage <- prop.table(table(training_set$Cover_Type)) * 100 
cbind(freq=table(training_set$Cover_Type), percentage=round(percentage, 2))
```


## 2. Algorithms
Machine learning in general uses training data set to train the model "Algorithm" to predict the results depending on the model. Piece of training data set plays as variables while the other piece is consedered as results. 
after that an estimation done using a validation set, which is a data set with known results but does not used in the process of training. 

```{r train control, echo=FALSE}
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
```

### 2.1 Algorithm 1 (linear algorithm): Linear discriminant analysis (L.D.A.)
Linear discriminant analysis (L.D.A.) is a method used in statistics and other fields to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resultant combination can be used as a linear classifier or, more typically, to reduce dimensionality before further classification. L.D.A. is closely connected to ANOVA and regression analysis, both of which aim to represent one dependent variable as a linear mixture of other traits or data. L.D.A. is a generalization of Fisher's linear discriminant. There is an option to extend the analysis used in the derivation of the Fisher discriminant to find a subspace that appears to contain all of the class variability when there are more than two classes. This generalization is due to C.R.Rao.

```{r lda algorithm, echo=FALSE}
gc()
memory.limit(9999999999)
gc()
set.seed(7,sample.kind = "Rejection")
fit.lda <- train(Cover_Type~., data=training_set, method="lda", metric=metric, trControl=control)
predect_lda<-predict(fit.lda, validation_set)
lda_conf_mat<-confusionMatrix(predect_lda, validation_set$Cover_Type)
```



### 2.2 Algorithm 2 ( nonlinear algorithm): Classification And Regression Tree (C.A.R.T)
The Classification and regression tree (C.A.R.T) approach is one of the most basic and oldest methods. It is used to forecast outcomes based on certain predictor factors. Because they need relatively minimal data pre-processing, they are ideal for data mining jobs. Decision tree models are simple to learn and apply, which provides them with a significant advantage over other analytical models. But trees can be very non-robust. A small change in the training data can result in a large change in the tree and consequently in the final predictions.

## 3. Results
### 3.1 Result of (L.D.A.) model
The following is the confusion matrix and statistics for L.D.A. model, with overall Accuracy  of `r lda_conf_mat$overall["Accuracy"] ` \ 

```{r lda confusion matrix, echo=FALSE}
lda_conf_mat
```


### 3.2 Result of (C.A.R.T) model
On the other hand, the C.A.R.T as a non-linear algorithm needs to be tuned for the complexity predictors "C.P.". In our model, we will try a C.P. array of length 20, with a minimum value of 0, and a maximum value of 0.05. The figure below shows that the best value of C.P which guarantees maximum accuracy is zero, i.e. Accuracy is max. when C.P.=0

```{r cart algorithm, echo=FALSE}
gc()
memory.limit(9999999999)
gc()
set.seed(7,sample.kind = "Rejection")
fit.cart <- train(Cover_Type~., data=training_set, method="rpart", metric=metric, trControl=control, tuneGrid = data.frame(cp = seq(0, 0.05, len = 20)))
ggplot(fit.cart, highlight = TRUE)+ ggtitle("Accuracy for each number of selected complexity  predictors")
ggsave("32.jpeg", width = 10, height = 8)
```


### 3.2.1 The optimal complexity parameter "C.P."
The complexity parameter (cp) is used to control the size of the decision tree and to select the optimal tree size. If the cost of adding another variable to the decision tree from the current node is above the value of cp, then tree building does not continue. We could also say that tree construction does not continue unless it would decrease the overall lack of fit by a factor of cp.

```{r complexity parameter, echo=FALSE}
opt_cp <- fit.cart$bestTune %>% as.numeric()
paste0("Optimal cp parameter = ", toString(round(opt_cp, 2)))
```



### 3.2.2 Redefine the model using the train_data and optimal cp

```{r Redefine cart, echo=FALSE}
gc()
memory.limit(9999999999)
gc()
model_rpart<-train(Cover_Type~., data=training_set, method="rpart", metric=metric, trControl=control, tuneGrid = data.frame(cp = opt_cp))
predect_cart<-predict(model_rpart, validation_set)
cart_conf_mat<-confusionMatrix(predect_cart, validation_set$Cover_Type)
```
Now we will re-train the model with the same data set but using the optimized value of the complexity predictors C.P., so the confusing matrix for the second algorithm after optimization shows how (C.A.R.T) foretell each cover type of forest and compare the prediction with the real cover type reference for each cover type "Levels", with overall Accuracy  of `r cart_conf_mat$overall["Accuracy"]`

```{r cart confusion matrix, echo=FALSE}
cart_conf_mat
```



### 3.3. Summarize accuracy of models

According to statistics, accuracy is the degree to which the information accurately describes the phenomena it is designed to measure. While the Kappa coefficient measures inter-rater reliability (as well as intra-rater reliability) and is commonly used in qualitative (categorical) items. Basically, rater reliability is an indication of how well the data collected by the study reflect the variables measured. The accuracy and Kappa of the two algorithms are compared in the figure below. The figure shows more high levels of "Accuracy" and inter-rater reliability "Kappa" for the C.A.R.T algorithm over the L.D.A. algorithm.

```{r accuracy of models lda and cart, echo=FALSE}
results <- resamples(list(lda=fit.lda, cart=model_rpart))
summary(results)
```



### 3.4. Compare accuracy and inter-rater reliability of models

```{r Comparing accuracy and inter-rater, echo=FALSE}
dotplot(results)
```


### 3.5. Estimating skill of C.A.R.T. on the validation dataset

```{r Estimating skill of C.A.R.T. on the validation dataset, echo=FALSE}
gc()
memory.limit(9999999999)
gc()
predictions <- predict(model_rpart, validation_set)
cart_conf_mat_validation<-confusionMatrix(predictions, validation_set$Cover_Type)
cart_conf_mat_validation
```

One of the most important steps during machine learning is to test the chosen algorithm using another data set "validation data set". Validation data set is a sub data set that is split from the original data set.
The overall "Accuracy" for the validation data set is `r cart_conf_mat_validation$overall["Accuracy"]`.
The following table depicts the statistical summary for the algorithm C.A.R.T. when using validation data set.


## 4. Conclusion 

In this paper machine learning is used to predict the forest cover type using two different models; a linear model: Linear discriminant analysis (L.D.A.) and a nonlinear model: Classification And Regression Tree (C.A.R.T).
Classification And Regression Tree (C.A.R.T) as a nonlinear algorithm shows its advantage over the Linear discriminant analysis (L.D.A.) as a linear algorithm when comparing Accuracy and intra-rater reliability for both. 

The Accuracy of C.A.R.T model is `r cart_conf_mat$overall["Accuracy"]`, while the accuracy of L.D.A. is `r lda_conf_mat$overall["Accuracy"]`
The intra-rater reliability for C.A.R.T model is `r cart_conf_mat$overall["Kappa"]`,
while the intra-rater reliability for L.D.A. is `r lda_conf_mat$overall["Kappa"]`.



